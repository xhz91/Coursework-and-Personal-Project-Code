{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/hx224/70016_nlp_coursework/nlpvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "if str(os.getcwd()).endswith('BertModel'):\n",
    "    os.chdir(\"..\")\n",
    "import sentencepiece\n",
    "from BertModel.Sampling import DataSampling\n",
    "from BertModel.Analyzer import BertAnalyzer\n",
    "from BertModel.PreTrainedBert import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dontpatronizeme_pcl.tsv'\n",
    "titles = ['par_id', 'art_id', 'keyword','country_code','text','label']\n",
    "raw_data = pd.read_csv(path, skiprows = 4, sep = '\\t',\n",
    "                       names = titles)\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data['label'] = np.where(raw_data['label'] > 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - validation (dev) - test split\n",
    "train = pd.read_csv(\"semeval-2022/practice splits/train_semeval_parids-labels.csv\")\n",
    "test = pd.read_csv(\"semeval-2022/practice splits/dev_semeval_parids-labels.csv\")\n",
    "train_df_official = raw_data[raw_data[\"par_id\"].isin(train['par_id'])]\n",
    "test_df = raw_data[raw_data[\"par_id\"].isin(test['par_id'])]\n",
    "\n",
    "train_data_shuffled = train_df_official.sample(frac = 1, random_state = 1).reset_index(drop = True)\n",
    "split_index = int(0.8 * len(train_data_shuffled))\n",
    "\n",
    "train_df = train_data_shuffled.iloc[:split_index]\n",
    "val_df = train_data_shuffled.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Processing Keywords:   0%|          | 0/10 [00:00<?, ?it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Processing Keywords: 100%|██████████| 10/10 [02:56<00:00, 17.68s/it]\n",
      "Processing Keywords: 100%|██████████| 10/10 [03:32<00:00, 21.25s/it]\n",
      "Processing Keywords: 100%|██████████| 10/10 [04:02<00:00, 24.25s/it]\n",
      "Processing Keywords: 100%|██████████| 10/10 [04:08<00:00, 24.86s/it]\n"
     ]
    }
   ],
   "source": [
    "datasampling = DataSampling()\n",
    "upsample_2 = datasampling.upsampling_with_mask_and_fill(raw_data=train_df, mask_ratio=0.2)\n",
    "upsample_4 = datasampling.upsampling_with_mask_and_fill(raw_data=train_df, mask_ratio=0.4)\n",
    "upsample_6 = datasampling.upsampling_with_mask_and_fill(raw_data=train_df, mask_ratio=0.6)\n",
    "upsample_8 = datasampling.upsampling_with_mask_and_fill(raw_data=train_df, mask_ratio=0.8)\n",
    "upsample_2.to_csv(\"upsample_2.csv\")\n",
    "upsample_4.to_csv(\"upsample_4.csv\")\n",
    "upsample_6.to_csv(\"upsample_6.csv\")\n",
    "upsample_8.to_csv(\"upsample_8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with mask_ratio=0.2, saving model to xlnet_analyzer_train_save/xlnet_analyzer_model_mask_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 1 -- batch: 10 -- avg loss: 0.6503\n",
      "epoch:, 1 -- batch: 20 -- avg loss: 0.3246\n",
      "epoch:, 1 -- batch: 30 -- avg loss: 0.2330\n",
      "epoch:, 1 -- batch: 40 -- avg loss: 0.1929\n",
      "epoch:, 1 -- batch: 50 -- avg loss: 0.1670\n",
      "epoch:, 1 -- batch: 60 -- avg loss: 0.1869\n",
      "epoch:, 1 -- batch: 70 -- avg loss: 0.1232\n",
      "epoch:, 1 -- batch: 80 -- avg loss: 0.1537\n",
      "epoch:, 1 -- batch: 90 -- avg loss: 0.1536\n",
      "epoch:, 1 -- batch: 100 -- avg loss: 0.1383\n",
      "epoch:, 1 -- batch: 110 -- avg loss: 0.1131\n",
      "epoch:, 1 -- batch: 120 -- avg loss: 0.1419\n",
      "epoch:, 1 -- batch: 130 -- avg loss: 0.1306\n",
      "epoch:, 1 -- batch: 140 -- avg loss: 0.0915\n",
      "epoch:, 1 -- batch: 150 -- avg loss: 0.1214\n",
      "epoch:, 1 -- batch: 160 -- avg loss: 0.1210\n",
      "epoch:, 1 -- batch: 170 -- avg loss: 0.1244\n",
      "epoch:, 1 -- batch: 180 -- avg loss: 0.1396\n",
      "epoch:, 1 -- batch: 190 -- avg loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 2 -- batch: 10 -- avg loss: 0.0586\n",
      "epoch:, 2 -- batch: 20 -- avg loss: 0.0419\n",
      "epoch:, 2 -- batch: 30 -- avg loss: 0.0321\n",
      "epoch:, 2 -- batch: 40 -- avg loss: 0.0315\n",
      "epoch:, 2 -- batch: 50 -- avg loss: 0.0356\n",
      "epoch:, 2 -- batch: 60 -- avg loss: 0.0609\n",
      "epoch:, 2 -- batch: 70 -- avg loss: 0.0346\n",
      "epoch:, 2 -- batch: 80 -- avg loss: 0.0427\n",
      "epoch:, 2 -- batch: 90 -- avg loss: 0.0415\n",
      "epoch:, 2 -- batch: 100 -- avg loss: 0.0517\n",
      "epoch:, 2 -- batch: 110 -- avg loss: 0.0468\n",
      "epoch:, 2 -- batch: 120 -- avg loss: 0.0568\n",
      "epoch:, 2 -- batch: 130 -- avg loss: 0.0419\n",
      "epoch:, 2 -- batch: 140 -- avg loss: 0.0474\n",
      "epoch:, 2 -- batch: 150 -- avg loss: 0.0300\n",
      "epoch:, 2 -- batch: 160 -- avg loss: 0.0376\n",
      "epoch:, 2 -- batch: 170 -- avg loss: 0.0632\n",
      "epoch:, 2 -- batch: 180 -- avg loss: 0.0513\n",
      "epoch:, 2 -- batch: 190 -- avg loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 3 -- batch: 10 -- avg loss: 0.0124\n",
      "epoch:, 3 -- batch: 20 -- avg loss: 0.0064\n",
      "epoch:, 3 -- batch: 30 -- avg loss: 0.0059\n",
      "epoch:, 3 -- batch: 40 -- avg loss: 0.0040\n",
      "epoch:, 3 -- batch: 50 -- avg loss: 0.0040\n",
      "epoch:, 3 -- batch: 60 -- avg loss: 0.0023\n",
      "epoch:, 3 -- batch: 70 -- avg loss: 0.0034\n",
      "epoch:, 3 -- batch: 80 -- avg loss: 0.0031\n",
      "epoch:, 3 -- batch: 90 -- avg loss: 0.0030\n",
      "epoch:, 3 -- batch: 100 -- avg loss: 0.0050\n",
      "epoch:, 3 -- batch: 110 -- avg loss: 0.0033\n",
      "epoch:, 3 -- batch: 120 -- avg loss: 0.0082\n",
      "epoch:, 3 -- batch: 130 -- avg loss: 0.0141\n",
      "epoch:, 3 -- batch: 140 -- avg loss: 0.0060\n",
      "epoch:, 3 -- batch: 150 -- avg loss: 0.0069\n",
      "epoch:, 3 -- batch: 160 -- avg loss: 0.0064\n",
      "epoch:, 3 -- batch: 170 -- avg loss: 0.0054\n",
      "epoch:, 3 -- batch: 180 -- avg loss: 0.0134\n",
      "epoch:, 3 -- batch: 190 -- avg loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 4 -- batch: 10 -- avg loss: 0.0011\n",
      "epoch:, 4 -- batch: 20 -- avg loss: 0.0021\n",
      "epoch:, 4 -- batch: 30 -- avg loss: 0.0018\n",
      "epoch:, 4 -- batch: 40 -- avg loss: 0.0026\n",
      "epoch:, 4 -- batch: 50 -- avg loss: 0.0016\n",
      "epoch:, 4 -- batch: 60 -- avg loss: 0.0008\n",
      "epoch:, 4 -- batch: 70 -- avg loss: 0.0025\n",
      "epoch:, 4 -- batch: 80 -- avg loss: 0.0005\n",
      "epoch:, 4 -- batch: 90 -- avg loss: 0.0012\n",
      "epoch:, 4 -- batch: 100 -- avg loss: 0.0005\n",
      "epoch:, 4 -- batch: 110 -- avg loss: 0.0005\n",
      "epoch:, 4 -- batch: 120 -- avg loss: 0.0005\n",
      "epoch:, 4 -- batch: 130 -- avg loss: 0.0004\n",
      "epoch:, 4 -- batch: 140 -- avg loss: 0.0030\n",
      "epoch:, 4 -- batch: 150 -- avg loss: 0.0014\n",
      "epoch:, 4 -- batch: 160 -- avg loss: 0.0060\n",
      "epoch:, 4 -- batch: 170 -- avg loss: 0.0024\n",
      "epoch:, 4 -- batch: 180 -- avg loss: 0.0007\n",
      "epoch:, 4 -- batch: 190 -- avg loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 5 -- batch: 10 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 20 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 30 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 40 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 50 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 60 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 70 -- avg loss: 0.0004\n",
      "epoch:, 5 -- batch: 80 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 90 -- avg loss: 0.0004\n",
      "epoch:, 5 -- batch: 100 -- avg loss: 0.0007\n",
      "epoch:, 5 -- batch: 110 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 120 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 130 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 140 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 150 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 160 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 170 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 180 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 190 -- avg loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9110\n",
      "Confusion Matrix:\n",
      "[[1471   54]\n",
      " [  95   55]]\n",
      "f1\n",
      "0.4247104247104247\n",
      "F1 Score on val_df for mask_ratio=0.2: 0.4247\n",
      "--------------------------------------------------\n",
      "Training with mask_ratio=0.4, saving model to xlnet_analyzer_train_save/xlnet_analyzer_model_mask_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 1 -- batch: 10 -- avg loss: 0.7740\n",
      "epoch:, 1 -- batch: 20 -- avg loss: 0.2294\n",
      "epoch:, 1 -- batch: 30 -- avg loss: 0.1900\n",
      "epoch:, 1 -- batch: 40 -- avg loss: 0.2057\n",
      "epoch:, 1 -- batch: 50 -- avg loss: 0.1395\n",
      "epoch:, 1 -- batch: 60 -- avg loss: 0.1277\n",
      "epoch:, 1 -- batch: 70 -- avg loss: 0.1492\n",
      "epoch:, 1 -- batch: 80 -- avg loss: 0.1291\n",
      "epoch:, 1 -- batch: 90 -- avg loss: 0.1338\n",
      "epoch:, 1 -- batch: 100 -- avg loss: 0.1264\n",
      "epoch:, 1 -- batch: 110 -- avg loss: 0.1322\n",
      "epoch:, 1 -- batch: 120 -- avg loss: 0.1602\n",
      "epoch:, 1 -- batch: 130 -- avg loss: 0.1257\n",
      "epoch:, 1 -- batch: 140 -- avg loss: 0.1514\n",
      "epoch:, 1 -- batch: 150 -- avg loss: 0.1100\n",
      "epoch:, 1 -- batch: 160 -- avg loss: 0.1234\n",
      "epoch:, 1 -- batch: 170 -- avg loss: 0.1116\n",
      "epoch:, 1 -- batch: 180 -- avg loss: 0.1175\n",
      "epoch:, 1 -- batch: 190 -- avg loss: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 2 -- batch: 10 -- avg loss: 0.0840\n",
      "epoch:, 2 -- batch: 20 -- avg loss: 0.0748\n",
      "epoch:, 2 -- batch: 30 -- avg loss: 0.0543\n",
      "epoch:, 2 -- batch: 40 -- avg loss: 0.0632\n",
      "epoch:, 2 -- batch: 50 -- avg loss: 0.0621\n",
      "epoch:, 2 -- batch: 60 -- avg loss: 0.0791\n",
      "epoch:, 2 -- batch: 70 -- avg loss: 0.0779\n",
      "epoch:, 2 -- batch: 80 -- avg loss: 0.0495\n",
      "epoch:, 2 -- batch: 90 -- avg loss: 0.0825\n",
      "epoch:, 2 -- batch: 100 -- avg loss: 0.0811\n",
      "epoch:, 2 -- batch: 110 -- avg loss: 0.0326\n",
      "epoch:, 2 -- batch: 120 -- avg loss: 0.0395\n",
      "epoch:, 2 -- batch: 130 -- avg loss: 0.0496\n",
      "epoch:, 2 -- batch: 140 -- avg loss: 0.0658\n",
      "epoch:, 2 -- batch: 150 -- avg loss: 0.1011\n",
      "epoch:, 2 -- batch: 160 -- avg loss: 0.0816\n",
      "epoch:, 2 -- batch: 170 -- avg loss: 0.0605\n",
      "epoch:, 2 -- batch: 180 -- avg loss: 0.0589\n",
      "epoch:, 2 -- batch: 190 -- avg loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 3 -- batch: 10 -- avg loss: 0.0340\n",
      "epoch:, 3 -- batch: 20 -- avg loss: 0.0308\n",
      "epoch:, 3 -- batch: 30 -- avg loss: 0.0416\n",
      "epoch:, 3 -- batch: 40 -- avg loss: 0.0259\n",
      "epoch:, 3 -- batch: 50 -- avg loss: 0.0195\n",
      "epoch:, 3 -- batch: 60 -- avg loss: 0.0166\n",
      "epoch:, 3 -- batch: 70 -- avg loss: 0.0074\n",
      "epoch:, 3 -- batch: 80 -- avg loss: 0.0070\n",
      "epoch:, 3 -- batch: 90 -- avg loss: 0.0113\n",
      "epoch:, 3 -- batch: 100 -- avg loss: 0.0105\n",
      "epoch:, 3 -- batch: 110 -- avg loss: 0.0102\n",
      "epoch:, 3 -- batch: 120 -- avg loss: 0.0277\n",
      "epoch:, 3 -- batch: 130 -- avg loss: 0.0258\n",
      "epoch:, 3 -- batch: 140 -- avg loss: 0.0152\n",
      "epoch:, 3 -- batch: 150 -- avg loss: 0.0090\n",
      "epoch:, 3 -- batch: 160 -- avg loss: 0.0095\n",
      "epoch:, 3 -- batch: 170 -- avg loss: 0.0156\n",
      "epoch:, 3 -- batch: 180 -- avg loss: 0.0161\n",
      "epoch:, 3 -- batch: 190 -- avg loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 4 -- batch: 10 -- avg loss: 0.0078\n",
      "epoch:, 4 -- batch: 20 -- avg loss: 0.0105\n",
      "epoch:, 4 -- batch: 30 -- avg loss: 0.0146\n",
      "epoch:, 4 -- batch: 40 -- avg loss: 0.0107\n",
      "epoch:, 4 -- batch: 50 -- avg loss: 0.0040\n",
      "epoch:, 4 -- batch: 60 -- avg loss: 0.0019\n",
      "epoch:, 4 -- batch: 70 -- avg loss: 0.0037\n",
      "epoch:, 4 -- batch: 80 -- avg loss: 0.0034\n",
      "epoch:, 4 -- batch: 90 -- avg loss: 0.0047\n",
      "epoch:, 4 -- batch: 100 -- avg loss: 0.0056\n",
      "epoch:, 4 -- batch: 110 -- avg loss: 0.0046\n",
      "epoch:, 4 -- batch: 120 -- avg loss: 0.0029\n",
      "epoch:, 4 -- batch: 130 -- avg loss: 0.0015\n",
      "epoch:, 4 -- batch: 140 -- avg loss: 0.0009\n",
      "epoch:, 4 -- batch: 150 -- avg loss: 0.0017\n",
      "epoch:, 4 -- batch: 160 -- avg loss: 0.0014\n",
      "epoch:, 4 -- batch: 170 -- avg loss: 0.0014\n",
      "epoch:, 4 -- batch: 180 -- avg loss: 0.0012\n",
      "epoch:, 4 -- batch: 190 -- avg loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 5 -- batch: 10 -- avg loss: 0.0005\n",
      "epoch:, 5 -- batch: 20 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 30 -- avg loss: 0.0008\n",
      "epoch:, 5 -- batch: 40 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 50 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 60 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 70 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 80 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 90 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 100 -- avg loss: 0.0016\n",
      "epoch:, 5 -- batch: 110 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 120 -- avg loss: 0.0004\n",
      "epoch:, 5 -- batch: 130 -- avg loss: 0.0004\n",
      "epoch:, 5 -- batch: 140 -- avg loss: 0.0007\n",
      "epoch:, 5 -- batch: 150 -- avg loss: 0.0008\n",
      "epoch:, 5 -- batch: 160 -- avg loss: 0.0001\n",
      "epoch:, 5 -- batch: 170 -- avg loss: 0.0002\n",
      "epoch:, 5 -- batch: 180 -- avg loss: 0.0007\n",
      "epoch:, 5 -- batch: 190 -- avg loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9110\n",
      "Confusion Matrix:\n",
      "[[1475   50]\n",
      " [  99   51]]\n",
      "f1\n",
      "0.4063745019920319\n",
      "F1 Score on val_df for mask_ratio=0.4: 0.4064\n",
      "--------------------------------------------------\n",
      "Training with mask_ratio=0.6, saving model to xlnet_analyzer_train_save/xlnet_analyzer_model_mask_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 1 -- batch: 10 -- avg loss: 0.4421\n",
      "epoch:, 1 -- batch: 20 -- avg loss: 0.2235\n",
      "epoch:, 1 -- batch: 30 -- avg loss: 0.2023\n",
      "epoch:, 1 -- batch: 40 -- avg loss: 0.1668\n",
      "epoch:, 1 -- batch: 50 -- avg loss: 0.1688\n",
      "epoch:, 1 -- batch: 60 -- avg loss: 0.1369\n",
      "epoch:, 1 -- batch: 70 -- avg loss: 0.1043\n",
      "epoch:, 1 -- batch: 80 -- avg loss: 0.1537\n",
      "epoch:, 1 -- batch: 90 -- avg loss: 0.1359\n",
      "epoch:, 1 -- batch: 100 -- avg loss: 0.1086\n",
      "epoch:, 1 -- batch: 110 -- avg loss: 0.1301\n",
      "epoch:, 1 -- batch: 120 -- avg loss: 0.1442\n",
      "epoch:, 1 -- batch: 130 -- avg loss: 0.0868\n",
      "epoch:, 1 -- batch: 140 -- avg loss: 0.1067\n",
      "epoch:, 1 -- batch: 150 -- avg loss: 0.0889\n",
      "epoch:, 1 -- batch: 160 -- avg loss: 0.1022\n",
      "epoch:, 1 -- batch: 170 -- avg loss: 0.1542\n",
      "epoch:, 1 -- batch: 180 -- avg loss: 0.1108\n",
      "epoch:, 1 -- batch: 190 -- avg loss: 0.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 2 -- batch: 10 -- avg loss: 0.0986\n",
      "epoch:, 2 -- batch: 20 -- avg loss: 0.0878\n",
      "epoch:, 2 -- batch: 30 -- avg loss: 0.0633\n",
      "epoch:, 2 -- batch: 40 -- avg loss: 0.0521\n",
      "epoch:, 2 -- batch: 50 -- avg loss: 0.0724\n",
      "epoch:, 2 -- batch: 60 -- avg loss: 0.0810\n",
      "epoch:, 2 -- batch: 70 -- avg loss: 0.0559\n",
      "epoch:, 2 -- batch: 80 -- avg loss: 0.0573\n",
      "epoch:, 2 -- batch: 90 -- avg loss: 0.0650\n",
      "epoch:, 2 -- batch: 100 -- avg loss: 0.0491\n",
      "epoch:, 2 -- batch: 110 -- avg loss: 0.0543\n",
      "epoch:, 2 -- batch: 120 -- avg loss: 0.0441\n",
      "epoch:, 2 -- batch: 130 -- avg loss: 0.0671\n",
      "epoch:, 2 -- batch: 140 -- avg loss: 0.0465\n",
      "epoch:, 2 -- batch: 150 -- avg loss: 0.0686\n",
      "epoch:, 2 -- batch: 160 -- avg loss: 0.0780\n",
      "epoch:, 2 -- batch: 170 -- avg loss: 0.0666\n",
      "epoch:, 2 -- batch: 180 -- avg loss: 0.0898\n",
      "epoch:, 2 -- batch: 190 -- avg loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 3 -- batch: 10 -- avg loss: 0.0252\n",
      "epoch:, 3 -- batch: 20 -- avg loss: 0.0145\n",
      "epoch:, 3 -- batch: 30 -- avg loss: 0.0073\n",
      "epoch:, 3 -- batch: 40 -- avg loss: 0.0121\n",
      "epoch:, 3 -- batch: 50 -- avg loss: 0.0068\n",
      "epoch:, 3 -- batch: 60 -- avg loss: 0.0214\n",
      "epoch:, 3 -- batch: 70 -- avg loss: 0.0477\n",
      "epoch:, 3 -- batch: 80 -- avg loss: 0.0414\n",
      "epoch:, 3 -- batch: 90 -- avg loss: 0.0411\n",
      "epoch:, 3 -- batch: 100 -- avg loss: 0.0440\n",
      "epoch:, 3 -- batch: 110 -- avg loss: 0.0351\n",
      "epoch:, 3 -- batch: 120 -- avg loss: 0.0707\n",
      "epoch:, 3 -- batch: 130 -- avg loss: 0.0720\n",
      "epoch:, 3 -- batch: 140 -- avg loss: 0.0351\n",
      "epoch:, 3 -- batch: 150 -- avg loss: 0.0220\n",
      "epoch:, 3 -- batch: 160 -- avg loss: 0.0237\n",
      "epoch:, 3 -- batch: 170 -- avg loss: 0.0316\n",
      "epoch:, 3 -- batch: 180 -- avg loss: 0.0182\n",
      "epoch:, 3 -- batch: 190 -- avg loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 4 -- batch: 10 -- avg loss: 0.0082\n",
      "epoch:, 4 -- batch: 20 -- avg loss: 0.0051\n",
      "epoch:, 4 -- batch: 30 -- avg loss: 0.0071\n",
      "epoch:, 4 -- batch: 40 -- avg loss: 0.0034\n",
      "epoch:, 4 -- batch: 50 -- avg loss: 0.0016\n",
      "epoch:, 4 -- batch: 60 -- avg loss: 0.0035\n",
      "epoch:, 4 -- batch: 70 -- avg loss: 0.0036\n",
      "epoch:, 4 -- batch: 80 -- avg loss: 0.0050\n",
      "epoch:, 4 -- batch: 90 -- avg loss: 0.0018\n",
      "epoch:, 4 -- batch: 100 -- avg loss: 0.0022\n",
      "epoch:, 4 -- batch: 110 -- avg loss: 0.0046\n",
      "epoch:, 4 -- batch: 120 -- avg loss: 0.0036\n",
      "epoch:, 4 -- batch: 130 -- avg loss: 0.0059\n",
      "epoch:, 4 -- batch: 140 -- avg loss: 0.0022\n",
      "epoch:, 4 -- batch: 150 -- avg loss: 0.0048\n",
      "epoch:, 4 -- batch: 160 -- avg loss: 0.0079\n",
      "epoch:, 4 -- batch: 170 -- avg loss: 0.0046\n",
      "epoch:, 4 -- batch: 180 -- avg loss: 0.0113\n",
      "epoch:, 4 -- batch: 190 -- avg loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 5 -- batch: 10 -- avg loss: 0.0009\n",
      "epoch:, 5 -- batch: 20 -- avg loss: 0.0010\n",
      "epoch:, 5 -- batch: 30 -- avg loss: 0.0009\n",
      "epoch:, 5 -- batch: 40 -- avg loss: 0.0007\n",
      "epoch:, 5 -- batch: 50 -- avg loss: 0.0013\n",
      "epoch:, 5 -- batch: 60 -- avg loss: 0.0006\n",
      "epoch:, 5 -- batch: 70 -- avg loss: 0.0014\n",
      "epoch:, 5 -- batch: 80 -- avg loss: 0.0003\n",
      "epoch:, 5 -- batch: 90 -- avg loss: 0.0004\n",
      "epoch:, 5 -- batch: 100 -- avg loss: 0.0012\n",
      "epoch:, 5 -- batch: 110 -- avg loss: 0.0008\n",
      "epoch:, 5 -- batch: 120 -- avg loss: 0.0007\n",
      "epoch:, 5 -- batch: 130 -- avg loss: 0.0010\n",
      "epoch:, 5 -- batch: 140 -- avg loss: 0.0009\n",
      "epoch:, 5 -- batch: 150 -- avg loss: 0.0056\n",
      "epoch:, 5 -- batch: 160 -- avg loss: 0.0049\n",
      "epoch:, 5 -- batch: 170 -- avg loss: 0.0012\n",
      "epoch:, 5 -- batch: 180 -- avg loss: 0.0064\n",
      "epoch:, 5 -- batch: 190 -- avg loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182\n",
      "Confusion Matrix:\n",
      "[[1522    3]\n",
      " [ 134   16]]\n",
      "f1\n",
      "0.1893491124260355\n",
      "F1 Score on val_df for mask_ratio=0.6: 0.1893\n",
      "--------------------------------------------------\n",
      "Training with mask_ratio=0.8, saving model to xlnet_analyzer_train_save/xlnet_analyzer_model_mask_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 1 -- batch: 10 -- avg loss: 0.8317\n",
      "epoch:, 1 -- batch: 20 -- avg loss: 0.2239\n",
      "epoch:, 1 -- batch: 30 -- avg loss: 0.1755\n",
      "epoch:, 1 -- batch: 40 -- avg loss: 0.1072\n",
      "epoch:, 1 -- batch: 50 -- avg loss: 0.1623\n",
      "epoch:, 1 -- batch: 60 -- avg loss: 0.1535\n",
      "epoch:, 1 -- batch: 70 -- avg loss: 0.1510\n",
      "epoch:, 1 -- batch: 80 -- avg loss: 0.1270\n",
      "epoch:, 1 -- batch: 90 -- avg loss: 0.1247\n",
      "epoch:, 1 -- batch: 100 -- avg loss: 0.1325\n",
      "epoch:, 1 -- batch: 110 -- avg loss: 0.1235\n",
      "epoch:, 1 -- batch: 120 -- avg loss: 0.1177\n",
      "epoch:, 1 -- batch: 130 -- avg loss: 0.1667\n",
      "epoch:, 1 -- batch: 140 -- avg loss: 0.1161\n",
      "epoch:, 1 -- batch: 150 -- avg loss: 0.1232\n",
      "epoch:, 1 -- batch: 160 -- avg loss: 0.1122\n",
      "epoch:, 1 -- batch: 170 -- avg loss: 0.1088\n",
      "epoch:, 1 -- batch: 180 -- avg loss: 0.1017\n",
      "epoch:, 1 -- batch: 190 -- avg loss: 0.1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 2 -- batch: 10 -- avg loss: 0.0901\n",
      "epoch:, 2 -- batch: 20 -- avg loss: 0.0621\n",
      "epoch:, 2 -- batch: 30 -- avg loss: 0.0899\n",
      "epoch:, 2 -- batch: 40 -- avg loss: 0.0814\n",
      "epoch:, 2 -- batch: 50 -- avg loss: 0.0802\n",
      "epoch:, 2 -- batch: 60 -- avg loss: 0.0638\n",
      "epoch:, 2 -- batch: 70 -- avg loss: 0.0657\n",
      "epoch:, 2 -- batch: 80 -- avg loss: 0.0804\n",
      "epoch:, 2 -- batch: 90 -- avg loss: 0.0712\n",
      "epoch:, 2 -- batch: 100 -- avg loss: 0.0519\n",
      "epoch:, 2 -- batch: 110 -- avg loss: 0.0593\n",
      "epoch:, 2 -- batch: 120 -- avg loss: 0.0617\n",
      "epoch:, 2 -- batch: 130 -- avg loss: 0.0771\n",
      "epoch:, 2 -- batch: 140 -- avg loss: 0.0965\n",
      "epoch:, 2 -- batch: 150 -- avg loss: 0.0893\n",
      "epoch:, 2 -- batch: 160 -- avg loss: 0.0916\n",
      "epoch:, 2 -- batch: 170 -- avg loss: 0.0790\n",
      "epoch:, 2 -- batch: 180 -- avg loss: 0.0704\n",
      "epoch:, 2 -- batch: 190 -- avg loss: 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 3 -- batch: 10 -- avg loss: 0.0292\n",
      "epoch:, 3 -- batch: 20 -- avg loss: 0.0166\n",
      "epoch:, 3 -- batch: 30 -- avg loss: 0.0225\n",
      "epoch:, 3 -- batch: 40 -- avg loss: 0.0130\n",
      "epoch:, 3 -- batch: 50 -- avg loss: 0.0292\n",
      "epoch:, 3 -- batch: 60 -- avg loss: 0.0226\n",
      "epoch:, 3 -- batch: 70 -- avg loss: 0.0409\n",
      "epoch:, 3 -- batch: 80 -- avg loss: 0.0142\n",
      "epoch:, 3 -- batch: 90 -- avg loss: 0.0225\n",
      "epoch:, 3 -- batch: 100 -- avg loss: 0.0257\n",
      "epoch:, 3 -- batch: 110 -- avg loss: 0.0163\n",
      "epoch:, 3 -- batch: 120 -- avg loss: 0.0198\n",
      "epoch:, 3 -- batch: 130 -- avg loss: 0.0168\n",
      "epoch:, 3 -- batch: 140 -- avg loss: 0.0167\n",
      "epoch:, 3 -- batch: 150 -- avg loss: 0.0151\n",
      "epoch:, 3 -- batch: 160 -- avg loss: 0.0212\n",
      "epoch:, 3 -- batch: 170 -- avg loss: 0.0192\n",
      "epoch:, 3 -- batch: 180 -- avg loss: 0.0353\n",
      "epoch:, 3 -- batch: 190 -- avg loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 4 -- batch: 10 -- avg loss: 0.0147\n",
      "epoch:, 4 -- batch: 20 -- avg loss: 0.0059\n",
      "epoch:, 4 -- batch: 30 -- avg loss: 0.0092\n",
      "epoch:, 4 -- batch: 40 -- avg loss: 0.0063\n",
      "epoch:, 4 -- batch: 50 -- avg loss: 0.0044\n",
      "epoch:, 4 -- batch: 60 -- avg loss: 0.0072\n",
      "epoch:, 4 -- batch: 70 -- avg loss: 0.0028\n",
      "epoch:, 4 -- batch: 80 -- avg loss: 0.0040\n",
      "epoch:, 4 -- batch: 90 -- avg loss: 0.0014\n",
      "epoch:, 4 -- batch: 100 -- avg loss: 0.0024\n",
      "epoch:, 4 -- batch: 110 -- avg loss: 0.0046\n",
      "epoch:, 4 -- batch: 120 -- avg loss: 0.0028\n",
      "epoch:, 4 -- batch: 130 -- avg loss: 0.0038\n",
      "epoch:, 4 -- batch: 140 -- avg loss: 0.0166\n",
      "epoch:, 4 -- batch: 150 -- avg loss: 0.0348\n",
      "epoch:, 4 -- batch: 160 -- avg loss: 0.0291\n",
      "epoch:, 4 -- batch: 170 -- avg loss: 0.0179\n",
      "epoch:, 4 -- batch: 180 -- avg loss: 0.0117\n",
      "epoch:, 4 -- batch: 190 -- avg loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:, 5 -- batch: 10 -- avg loss: 0.0169\n",
      "epoch:, 5 -- batch: 20 -- avg loss: 0.0079\n",
      "epoch:, 5 -- batch: 30 -- avg loss: 0.0040\n",
      "epoch:, 5 -- batch: 40 -- avg loss: 0.0161\n",
      "epoch:, 5 -- batch: 50 -- avg loss: 0.0055\n",
      "epoch:, 5 -- batch: 60 -- avg loss: 0.0089\n",
      "epoch:, 5 -- batch: 70 -- avg loss: 0.0067\n",
      "epoch:, 5 -- batch: 80 -- avg loss: 0.0059\n",
      "epoch:, 5 -- batch: 90 -- avg loss: 0.0078\n",
      "epoch:, 5 -- batch: 100 -- avg loss: 0.0088\n",
      "epoch:, 5 -- batch: 110 -- avg loss: 0.0039\n",
      "epoch:, 5 -- batch: 120 -- avg loss: 0.0089\n",
      "epoch:, 5 -- batch: 130 -- avg loss: 0.0064\n",
      "epoch:, 5 -- batch: 140 -- avg loss: 0.0082\n",
      "epoch:, 5 -- batch: 150 -- avg loss: 0.0068\n",
      "epoch:, 5 -- batch: 160 -- avg loss: 0.0032\n",
      "epoch:, 5 -- batch: 170 -- avg loss: 0.0085\n",
      "epoch:, 5 -- batch: 180 -- avg loss: 0.0094\n",
      "epoch:, 5 -- batch: 190 -- avg loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182\n",
      "Confusion Matrix:\n",
      "[[1493   32]\n",
      " [ 105   45]]\n",
      "f1\n",
      "0.3964757709251101\n",
      "F1 Score on val_df for mask_ratio=0.8: 0.3965\n",
      "--------------------------------------------------\n",
      "Best Model: xlnet_analyzer_train_save/xlnet_analyzer_model_mask_2.pth with mask_ratio=0.2 and F1 Score=0.4247\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"xlnet_analyzer_train_save\"\n",
    "mask_ratios = [0.2, 0.4, 0.6, 0.8]\n",
    "data_files = [\"upsample_2.csv\", \"upsample_4.csv\", \"upsample_6.csv\", \"upsample_8.csv\"]\n",
    "\n",
    "# Track best model\n",
    "best_f1 = 0\n",
    "best_model_path = None\n",
    "best_mask_ratio = None\n",
    "\n",
    "for mask_ratio, file_path in zip(mask_ratios, data_files):\n",
    "    save_path = os.path.join(save_dir, f\"xlnet_analyzer_model_mask_{int(mask_ratio * 10)}.pth\")\n",
    "\n",
    "    # Load the dataset from CSV\n",
    "    train_df = pd.read_csv(file_path)  # FIX: Load CSV before passing to BertAnalyzer.train()\n",
    "\n",
    "    # Initialize model\n",
    "    xlnet_model = model(\"xlnet-base-cased\")\n",
    "\n",
    "    xlnet_analyzer = BertAnalyzer(model=xlnet_model,\n",
    "                                  batch_size=64,\n",
    "                                  max_seq_len=128,\n",
    "                                  epochs=5,\n",
    "                                  lr=4e-05)\n",
    "\n",
    "    print(f\"Training with mask_ratio={mask_ratio}, saving model to {save_path}\")\n",
    "\n",
    "    # Train and save the model\n",
    "    xlnet_analyzer.train(data_file=train_df, save_path=save_path)  # Pass the loaded DataFrame\n",
    "\n",
    "    # Evaluate model on validation set (val_df)\n",
    "    f1_score = xlnet_analyzer.evaluate(val_df)  # val_df should NOT be upsampled\n",
    "\n",
    "    print(f\"F1 Score on val_df for mask_ratio={mask_ratio}: {f1_score:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Track the best model\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_model_path = save_path\n",
    "        best_mask_ratio = mask_ratio\n",
    "        \n",
    "    del xlnet_model\n",
    "    del xlnet_analyzer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Print the best model and mask ratio\n",
    "print(f\"Best Model: {best_model_path} with mask_ratio={best_mask_ratio} and F1 Score={best_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
